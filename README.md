# Research Publication Search Engine + Document Classification

**Coventry University - Information Retrieval Assignment**  
**Student**: Rishesh Shrestha  
**Module**: ST7071CEM - Intelligent Information Retrieval

---

## ðŸš€ Quick Start

### Run Everything with One Command:
```bash
python run_project.py
```

This will:
- âœ… Start Django backend (http://127.0.0.1:8000)
- âœ… Start React frontend (http://localhost:5173)
- âœ… Open browser automatically

**Stop servers**: Press `Ctrl+C`

---

## ðŸ“‹ Project Overview

This project implements two main tasks:

### Task 1: Vertical Search Engine
- Web crawler for Coventry University research publications
- Inverted index construction
- Query processor with relevance ranking
- **Access**: http://localhost:5173/

### Task 2: Document Classification
- Multinomial NaÃ¯ve Bayes classifier
- TF-IDF feature extraction
- Three categories: Business, Entertainment, Health
- **Access**: http://localhost:5173/classification

---

## ðŸ“‚ Project Structure

```
final task/
â”œâ”€â”€ backend/                    # Django backend
â”‚   â”œâ”€â”€ classification/         # Task 2: Document classification
â”‚   â”œâ”€â”€ search_engine/          # Task 1: Search engine
â”‚   â”œâ”€â”€ models/                 # Trained ML models
â”‚   â””â”€â”€ data/                   # Datasets and metrics
â”œâ”€â”€ frontend/                   # React frontend
â”‚   â””â”€â”€ src/components/         # UI components
â”œâ”€â”€ run_project.py              # ðŸŽ¯ Main launcher (run this!)
â”œâ”€â”€ run_task2_classification.py # Train classification model
â”œâ”€â”€ generate_dataset.py         # Generate training data
â””â”€â”€ TASK2_*.md                  # Documentation files
```

---

## ðŸŽ¯ Available Pages

| Page | URL | Description |
|------|-----|-------------|
| Search Engine | http://localhost:5173/ | Search research publications |
| Classification | http://localhost:5173/classification | Classify documents |
| Statistics | http://localhost:5173/stats | View clustering statistics |
| Crawler | http://localhost:5173/crawl | Web crawler interface |

---

## ðŸ“Š Task 2 Model Performance

- **Accuracy**: 90% (on real-world news data)
- **Categories**: Business, Entertainment, Health
- **Dataset**: 150 real-world articles from BBC News & The Guardian
- **Distribution**: 50 documents per category
- **Algorithm**: Multinomial NaÃ¯ve Bayes
- **Features**: TF-IDF with bigrams

### Per-Category Performance
| Category | Precision | Recall | F1-Score |
|----------|-----------|--------|----------|
| Business | 100% | 70% | 82% |
| Entertainment | 91% | 100% | 95% |
| Health | 83% | 100% | 91% |

---

## ðŸ”§ Manual Setup (if needed)

### 1. Install Dependencies
```bash
# Backend
cd backend
pip install -r requirements.txt

# Frontend
cd frontend
npm install
```

### 2. Train Classification Model
```bash
python run_task2_classification.py
```

### 3. Run Servers Separately
```bash
# Terminal 1 - Backend
cd backend
python manage.py runserver

# Terminal 2 - Frontend
cd frontend
npm run dev
```

---

## ðŸ“– Documentation

- **TASK2_SUMMARY.md** - Complete implementation overview
- **TASK2_DOCUMENTATION.md** - Technical documentation
- **TASK2_QUICK_REFERENCE.md** - Quick commands and tips
- **TASK2_ARCHITECTURE.md** - System architecture diagrams

---

## âœ… Assignment Requirements

### Task 1: Search Engine
- âœ… Web crawler (BFS, robots.txt compliant)
- âœ… Inverted index construction
- âœ… Query processor with ranking
- âœ… Web interface

### Task 2: Document Classification
- âœ… 120 labeled documents (3 categories)
- âœ… Multinomial NaÃ¯ve Bayes classifier
- âœ… TF-IDF features with preprocessing
- âœ… Model evaluation (accuracy, precision, recall, F1)
- âœ… Robustness testing (varied inputs)
- âœ… Web interface for predictions
- âœ… API endpoints

---

## ðŸ§ª Testing

### Test Classification API
```bash
python test_classification_api.py
```

### Example Predictions
- "The central bank increased interest rates" â†’ **Business**
- "The actor won an award for his movie" â†’ **Entertainment**
- "Doctors warn about rising flu cases" â†’ **Health**

---

## ðŸŽ“ For Report/Viva

### Screenshots to Take:
1. Training output from `run_task2_classification.py`
2. Web interface showing predictions
3. API responses with confidence scores
4. Search engine results
5. Crawler in action

### Key Points to Explain:
- Why Multinomial NaÃ¯ve Bayes for text classification
- How TF-IDF works and why bigrams are used
- Preprocessing pipeline
- Model evaluation metrics
- Robustness testing results

---

## ðŸ’¡ Tips

- **First time running?** Just use `python run_project.py`
- **Model not found?** Run `python run_task2_classification.py` first
- **Port conflicts?** Check if ports 8000 or 5173 are already in use
- **Need help?** Check the TASK2_*.md documentation files

---

## ðŸ“ž Support

If you encounter issues:
1. **Check TROUBLESHOOTING.md** for common issues and solutions
2. Ensure Python dependencies are installed: `pip install -r backend/requirements.txt`
3. Ensure Node dependencies are installed: `cmd /c npm install` (in frontend/)
4. Check that ports 8000 and 5173 are available
5. Review documentation files for detailed instructions

**PowerShell Issues?** The script now uses `cmd /c npm` to avoid execution policy errors.

---

**Status**: âœ… Complete and Ready for Submission  
**Last Updated**: 2026-01-22
